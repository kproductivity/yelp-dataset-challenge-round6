---
title: "Task 0 - Get the data"
author: "Francisco Marco-Serrano"
output: html_document
---

The first step in analysing any new data set is figuring out: (a) what data you have and (b) what are the standard tools and models used for that type of data. The dataset provided here is part of the Yelp Dataset Challenge and the specific dataset used in here corresponds to Round 6 of their challenge. The dataset is approximately 575MB.

Data: https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/yelp_dataset_challenge_academic_dataset.zip


```{r}
library(jsonlite)

readmyJSON <- function(myfile){
  # See http://stackoverflow.com/a/26522000 for overcoming 'Error in
  # feed_push_parser...'
  # df <- fromJSON(sprintf("[%s]", paste(readLines(myfile), collapse=",")))
  
  # See http://stackoverflow.com/questions/29688946/reading-a-huge-json-file-in-r-issues
  df <- stream_in(file(myfile), pagesize = 10000)

  dim(df)
  names(df)
  df
} 


biz.df <- readmyJSON('./data/yelp_academic_dataset_business.json')
saveRDS(biz.df, file="./data/biz.RData")
rm(biz.df)

checkin.df <- readmyJSON('./data/yelp_academic_dataset_checkin.json')
saveRDS(checkin.df, file="./data/checkin.RData")
rm(checkin.df)

review.df <- readmyJSON('./data/yelp_academic_dataset_review.json')
saveRDS(review.df, file="./data/review.RData")
rm(review.df)

tip.df <- readmyJSON('./data/yelp_academic_dataset_tip.json')
saveRDS(tip.df, file="./data/tip.RData")
rm(tip.df)

user.df <- readmyJSON('./data/yelp_academic_dataset_user.json')
saveRDS(user.df, file="./data/user.RData")
rm(user.df)

```

##Alternative solution for low-mem systems
```{r}

start.time <- proc.time()

#Read json file
require(jsonlite)
#See http://www.r-bloggers.com/iterators-in-r/
require(itertools)
myfile <- './data/yelp_academic_dataset_review.json'
con <- ihasNext(ireadLines(myfile))

df <- data.frame()
numfile <- 1

#process each line and store in raw CSV
while (hasNext(con)) {
    d <- nextElem(con)
    df <- as.data.frame(fromJSON(d))
    write.csv(df, file=paste("./data/reviews/reviews", numfile, ".csv", sep=""), sep=",", row.names="F")
    numfile <- numfile+1
}

#read files and merge
#See http://www.r-bloggers.com/merging-multiple-data-files-into-one-data-frame/
multmerge <- function(){
    myfiles <- list.files(path="./data/", pattern=".csv", full.names = T)
    datalist <- lapply(myfiles, function(x){read.csv(file=x,header=T)})
    Reduce(function(x,y) {merge(x,y)}, datalist)
    }

saveRDS(df, file="./data/review.RData")

proc.time() - start.time

```

##Tasks to accomplish

* Learn about Yelp and what kinds of data it collects
* Obtaining the data - Can you download the data and load it in R?
* Familiarising with the metadata - What features/variables are included? What data is stored in each of the different files? How can you link the information from the different files together?

##Questions to consider

* What do the data look like?
* Where do the data come from?
* Can we think of any other data sources that might help us in this project?
* What are some common issues in the analysis of text data?